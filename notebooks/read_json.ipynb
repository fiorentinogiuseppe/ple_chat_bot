{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from  pathlib import Path\n",
    "path = Path(\"../resources/ufrpe/qa.txt\")\n",
    "with open(path, 'r') as f:\n",
    "    object_list = []\n",
    "    for line in f.readlines():\n",
    "        object_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "contexts = []\n",
    "questions = []\n",
    "answers = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "for i in object_list:\n",
    "    questions.append(i['pergunta'])\n",
    "    answers.append(i['resposta'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BertForQuestionAnswering'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-9654ac0a6bd0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mBertForQuestionAnswering\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBertForQuestionAnswering\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'neuralmind/bert-base-portuguese-cased'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'BertForQuestionAnswering'"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('neuralmind/bert-base-portuguese-cased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 42 tokens.\n"
     ]
    }
   ],
   "source": [
    "question = \"Quando começam as aulas do PLE?\"\n",
    "answer_text = \"O primeiro PLE (2020.3) iniciará no dia 17 de agosto. Confira o Calendário Acadêmico com todas as datas\"\n",
    "input_ids = tokenizer.encode(question, answer_text)\n",
    "print('The input has a total of {:} tokens.'.format(len(input_ids)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "Quando        1,643\n",
      "começam       8,749\n",
      "as              260\n",
      "aulas         6,880\n",
      "do              171\n",
      "P               212\n",
      "##L          22,327\n",
      "##E          22,309\n",
      "?               136\n",
      "\n",
      "[SEP]           102\n",
      "\n",
      "O               231\n",
      "primeiro        652\n",
      "P               212\n",
      "##L          22,327\n",
      "##E          22,309\n",
      "(               113\n",
      "202          14,979\n",
      "##0          22,307\n",
      ".               119\n",
      "3               511\n",
      ")               114\n",
      "iniciar       9,070\n",
      "##á          22,303\n",
      "no              202\n",
      "dia             644\n",
      "17            1,040\n",
      "de              125\n",
      "agosto        1,600\n",
      ".               119\n",
      "Conf          9,425\n",
      "##ira           364\n",
      "o               146\n",
      "Cale         21,716\n",
      "##ndário      7,566\n",
      "Acadêm       18,290\n",
      "##ico           319\n",
      "com             170\n",
      "todas         1,485\n",
      "as              260\n",
      "datas        10,995\n",
      "\n",
      "[SEP]           102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BERT only needs the token IDs, but for the purpose of inspecting the\n",
    "# tokenizer's behavior, let's also get the token strings and display them.\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# For each token and its id...\n",
    "for token, id in zip(tokens, input_ids):\n",
    "\n",
    "    # If this is the [SEP] token, add some space around it to make it stand out.\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "\n",
    "    # Print the token string and its ID in two columns.\n",
    "    print('{:<12} {:>6,}'.format(token, id))\n",
    "\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Search the input_ids for the first instance of the `[SEP]` token.\n",
    "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "# The number of segment A tokens includes the [SEP] token istelf.\n",
    "num_seg_a = sep_index + 1\n",
    "\n",
    "# The remainder are segment B.\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "# Construct the list of 0s and 1s.\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "# There should be a segment_id for every input token.\n",
    "assert len(segment_ids) == len(input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-4220ed8c87d4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Run our example through the model.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n\u001B[0m\u001B[1;32m      3\u001B[0m                                  token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Run our example through the model.\n",
    "start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                 token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "answer_start = torch.argmax(start_scores)\n",
    "answer_end = torch.argmax(end_scores)\n",
    "\n",
    "# Combine the tokens in the answer and print it out.\n",
    "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
    "\n",
    "print('Answer: \"' + answer + '\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Referencia\n",
    "* https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/\n",
    "* https://medium.com/datadriveninvestor/extending-google-bert-as-question-and-answering-model-and-chatbot-e3e7b47b721a\n",
    "  * Com preparação dos dados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}